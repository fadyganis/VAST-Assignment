---
title: "Methodology & Data Preparation"
site: distill::distill_website
toc: TRUE
toc_depth: 3
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(knitr)
library(tidyverse)
library(clock)
library(raster)
library(sf)
library(DT)
library(tmap)
```

<h2> Methodology </h2>

<p>
With the objectives sorted out as well as, the way to solve each problem can be planned in advanced by visualizing the following graphs.
</p>

<p>
1.	Heatmap of businesses by each period, this would highlight popular places in a timeframe based on the number of transactions happening.
2.	A map of the region with points showing the start and end point of each trip would give meaning to the popularity of the places as well as could find new leads regarding the routines of each employee.
3.	The combination of the loyalty card data as well as the routine of the employees acquired from the vehicle data would give a possibility of which card belonging to which employee. However, multiple employees in the same place at the same time would make this impossible. 
4.	Network graph to show non-professional relationships between employees.
5.	A combination of the above visualizations would be enough to infer any suspicious activities done by the employees. Therefore, no additional visualizations would be needed.
</p>

<h2> Data Preparation </h2>

<p>
To start the investigation, the dataset must first be prepared to be able to be properly plotted which will be discussed in this sub-section.
</p>

<h3> Transaction Heatmap </h3>
<p>
To begin with, this part will utilize the "cc_data" and "loyalty_data" csv files. Some problems found and how it is solved are listed below.
</p>

1. Incorrect data formats
```{r,echo=TRUE}
cc <- read.csv("_site/cc_data.csv")
loyalty <- read.csv("_site/loyalty_data.csv")
print(str(cc))
print(str(loyalty))
```
<p>
As can be seen above, the first thing needed to be fixed is the timestamp columns of each dataframe since they are still reported as "character" instead of a "datetime" format. This is done by extracting the date using the "date_time_parse" function from the "clock" library.
</p>
```{r,echo=TRUE}
cc$timestamp <-  date_time_parse(cc$timestamp,zone = "", format = "%m/%d/%Y %H:%M")
loyalty$timestamp <-  date_time_parse(loyalty$timestamp,zone = "", format = "%m/%d/%Y")

print(str(cc))
print(str(loyalty))
```
2. Create new dataframes
<p>
The heatmap is planned to analyze a combination of credit cards, loyalty cards, number of transactions and revenue. As such different dataframes must be prepared in order to successfully visualize all aspects.
</p>
```{r,echo=TRUE}
## Extract hour row from cc data


cc$H <-  format(cc$timestamp, format='%H')

## Create only mdy column in cc for matching with loyalty

cc$mdy <- format(cc$timestamp, format = "%m/%d/%Y")
cc$mdy <- date_time_parse(cc$mdy,zone = "",format = "%m/%d/%Y")

## Extract transactions that use loyalty card but not CC using dplyr

loy_only <-  anti_join(loyalty,cc,by=c("location","price","timestamp"="mdy"))

## Extract transactions that use cc only

cc_only <- anti_join(cc,loyalty,by=c("location","price","mdy"="timestamp"))

## Create transactions that use both

cc_loy_union <- merge(cc,loyalty,by.x=c("location","price","mdy"),by.y=c("location","price","timestamp"),all=TRUE)

cc_loy_clean <-  na.omit(cc_loy_union)
row.names(cc_loy_clean) <- NULL
```

<p>
Once the dataframes has been created, the plotting follows the same code chunk shown below.
</p>
```{r,echo=TRUE}
library(viridis)
library(ggplot2)
library(hrbrthemes)
library(plotly)

x <- paste("H",seq(0,23),sep="")
y <- sort(unique(cc$location))
data <- expand.grid(X=x, Y=y)
data$H <- seq(0,23)

for(i in 1:nrow(data)){
  data$Z[i] =  nrow(cc_loy_clean[cc_loy_clean$location == data$Y[i] 
                                 & cc_loy_clean$H == data$H[i],])
}

data <- data %>%
  mutate(text = paste0("Hour: ", X, "\n","Location: ", Y, "\n","Number of Transactions: ", Z, "\n"))

p <- ggplot(data, aes(X, Y, fill= Z,text=text)) + 
  geom_tile() +
  scale_fill_viridis(discrete=FALSE) +
  theme_ipsum()

plot1 <- ggplotly(p, tooltip="text")
```
```{r,echo=FALSE,layout="1-body-outset",fig.height=7}
plot1
```

<h3> GPS Movements </h3>

<p>
Tracking the GPS movements is a more demanding task considering the sheer size of the dataset. However, as discussed in the methodology, only the start and endpoint will be considered for plotting. This section will discuss how to filter said data as well as how to plot the data on top of an overlay image of the map of Kronos.
</p>

<h4> Filter Only Start and End Points </h4>

<p>
To start, the dataset is first imported.
</p>

```{r,echo=TRUE}
gps <- read.csv("_site/gps.csv")
glimpse(gps)
```

<p>
The "Timestamp" column is shown still in "character" and will be changed into datetime.
</p>
```{r,echo=TRUE}
gps$Timestamp <- date_time_parse(gps$Timestamp, zone = "", format = "%m/%d/%Y %H:%M:%S")
glimpse(gps)
```
<p>
The latitude and longitude coordinates are also then combined to a single column by changing the dataframe into a shapefile suitable for plotting using the library "sf".
</p>
```{r,echo=TRUE}
gps_sf = st_as_sf(gps, coords = c("long","lat"), crs = 4326)
```
<p>
Before the data can be extracted by start and endpoint, the dataframe must first be sorted by id and time for the extraction code to work.
</p>

```{r,echo=TRUE}
gps_sf2 <-  arrange(gps_sf,id,Timestamp)
```
<p>
The above code chunk would sort the dataframe by id first and then by timestamp. Once that is done the start and end point is filtered by checking the difference between each timestamp interval. 
</p>
<p>
To elaborate, the GPS data records the data every few seconds. As such, a trip would mean that the start to end point will have a difference of minutes. Therefore the points can be determined using the following code.
</p>
```{r,echo=TRUE}
x <- 0
for(i in 2:(nrow(gps_sf2)-1)){
  if(difftime(gps_sf2$Timestamp[i+1],gps_sf2$Timestamp[i],units = "mins") < 0.5 &
     difftime(gps_sf2$Timestamp[i],gps_sf2$Timestamp[i-1],units = "mins")
     < 0.5 & gps_sf2$id[i] == gps_sf2$id[i+1] & gps_sf2$id[i] == gps_sf2$id[i-1]){
    x <- c(x,i)
  }
}
gps_sf2 <- gps_sf2[-x,]
row.names(gps_sf2) <- NULL
datatable(head(gps_sf2,100))
```
<p>
The next step is to then input employee details based on the id number for ease of identification during plotting.
</p>
```{r,echo=TRUE}
car <- read.csv("_site/car-assignments.csv")
car$Name <- paste(car$FirstName,car$LastName,sep=" ")

for(x in 1:nrow(gps_sf2)){
  ifelse(gps_sf2$id[x] %in% car$CarID == TRUE,
         {gps_sf2$Name[x] <- car$Name[which(car$CarID == gps_sf2$id[x])];
         gps_sf2$Position[x] <- car$CurrentEmploymentTitle[which(car$CarID == gps_sf2$id[x])];
         gps_sf2$Department[x] <- car$CurrentEmploymentType[which(car$CarID == gps_sf2$id[x])]},
         {gps_sf2$Name[x] <- paste("Truck",gps_sf2$id[x],sep=" ");
         gps_sf2$Position[x] <- paste("Truck",gps_sf2$id[x],sep=" ");
         gps_sf2$Department[x] <-paste("Truck",gps_sf2$id[x],sep=" ")})}

datatable(head(gps_sf2,100))
```
<p>
With that out of the way, the next step is to then plot the map.
</p>

<h4> Map Plot </h4>
<p>
To begin plotting the map, the image file is first imported as a raster using the "raster" library.
</p>
```{r,echo=TRUE}
bgmap <- raster('_site/MC2-tourist.tif')
```
<p>
And to plot the gps point, simply use the "tmap" library with the imported raster and the filtered GPS dataset. The dots will be color coded based on the "Name" column.
</p>
```{r,echo=TRUE}
tmap_mode("view")

tm_shape(bgmap)+
tm_rgb(bgmap, r =1, g = 2, b = 3, alpha=NA, saturation = 1, interpolate = TRUE, max.value = 255) +
tm_shape(gps_sf2) + tm_dots(col="Name") + tmap_options(max.categories = 50)
```